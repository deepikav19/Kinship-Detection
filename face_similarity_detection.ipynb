{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MveqxSiDSHgE",
    "outputId": "2cdc40f4-66be-4ca2-8e45-f1625165c287"
   },
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlX-N0REYtIK",
    "outputId": "57de4eb4-623d-47b0-b44f-5e24deaeca7f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCpNQWNdTBQm"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx6OelcOZTPK"
   },
   "outputs": [],
   "source": [
    "WOMAN_IMAGE_PATH = \"drive/MyDrive/images/ms_001_1.jpg\"\n",
    "MAN_IMAGE_PATH = \"drive/MyDrive/images/ms_001_2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "5sKXWjqEXBMG",
    "outputId": "a0f7b8ac-2b1e-4db5-b7eb-63ab4409249f"
   },
   "outputs": [],
   "source": [
    "woman = Image.open(WOMAN_IMAGE_PATH)\n",
    "display(woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "eZ86dDZXZKJT",
    "outputId": "45e4e602-e39e-474a-91ad-f04261adafaf"
   },
   "outputs": [],
   "source": [
    "man = Image.open(MAN_IMAGE_PATH)\n",
    "display(man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkdJV_XUZNYI",
    "outputId": "e54c4d91-5653-4652-a8d6-eecfce61f012"
   },
   "outputs": [],
   "source": [
    "image_array1 = face_recognition.load_image_file(WOMAN_IMAGE_PATH)\n",
    "image_array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pi-3MTUhZjp5",
    "outputId": "8c4411d4-ff1a-4892-eef4-19d221640106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 79,  48,  30],\n",
       "        [101,  66,  47],\n",
       "        [125,  87,  66],\n",
       "        ...,\n",
       "        [103,  80,  64],\n",
       "        [ 81,  64,  48],\n",
       "        [ 64,  51,  34]],\n",
       "\n",
       "       [[ 83,  52,  32],\n",
       "        [102,  67,  48],\n",
       "        [126,  85,  65],\n",
       "        ...,\n",
       "        [101,  78,  62],\n",
       "        [ 81,  64,  48],\n",
       "        [ 66,  53,  36]],\n",
       "\n",
       "       [[ 85,  52,  33],\n",
       "        [ 99,  64,  45],\n",
       "        [119,  78,  58],\n",
       "        ...,\n",
       "        [ 98,  75,  59],\n",
       "        [ 81,  64,  48],\n",
       "        [ 68,  55,  38]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 57,  41,  16],\n",
       "        [ 58,  38,  14],\n",
       "        [ 65,  37,  16],\n",
       "        ...,\n",
       "        [203, 162,  98],\n",
       "        [210, 166, 101],\n",
       "        [201, 158,  90]],\n",
       "\n",
       "       [[ 54,  40,  14],\n",
       "        [ 53,  35,  11],\n",
       "        [ 61,  34,  13],\n",
       "        ...,\n",
       "        [206, 165, 101],\n",
       "        [205, 161,  96],\n",
       "        [208, 163,  96]],\n",
       "\n",
       "       [[ 52,  37,  14],\n",
       "        [ 51,  33,  11],\n",
       "        [ 59,  32,  11],\n",
       "        ...,\n",
       "        [208, 167, 103],\n",
       "        [200, 157,  89],\n",
       "        [213, 168, 101]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array2 = face_recognition.load_image_file(MAN_IMAGE_PATH)\n",
    "image_array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cuHPGYuZvGN"
   },
   "source": [
    "IDENTIFY FACE LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jFR1mwTZ4Sg",
    "outputId": "71adf259-2b9a-49ee-c231-6573b739185a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 64, 64, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations1 = face_recognition.face_locations(image_array1)\n",
    "face_locations1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehosWAmLZ7NZ",
    "outputId": "61aefd2e-689e-4cb7-cd6c-9ad849ca6192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 64, 64, 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations2 = face_recognition.face_locations(image_array2)\n",
    "face_locations2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pj1mCHf4aWLY",
    "outputId": "17b1da65-1c87-48df-8683-d7b943d2e41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.51630771e-02,  1.00319862e-01,  1.19007140e-01,  2.45287120e-02,\n",
       "       -9.43189040e-02, -2.33089328e-02, -2.78661363e-02, -1.53453529e-01,\n",
       "        1.23658478e-01, -1.67898551e-01,  2.48847887e-01, -4.41675335e-02,\n",
       "       -2.79760957e-01,  8.63008946e-03, -3.69810462e-02,  1.26763359e-01,\n",
       "       -1.62767142e-01, -9.97723937e-02, -8.73778760e-02, -3.27207968e-02,\n",
       "        2.32717842e-02,  5.52876554e-02,  3.23899910e-02, -6.82633370e-02,\n",
       "       -4.80496883e-02, -2.91477978e-01, -5.88705987e-02, -2.37120949e-02,\n",
       "        8.98295641e-02, -1.56061798e-02,  5.17715067e-02,  2.22180020e-02,\n",
       "       -1.90829054e-01, -3.07739303e-02, -1.29676685e-02,  1.22230776e-01,\n",
       "       -1.45492941e-01, -4.68413383e-02,  2.17961341e-01, -3.89367789e-02,\n",
       "       -1.58927783e-01, -2.02130601e-02, -1.28226876e-02,  2.20638886e-01,\n",
       "        1.80637807e-01,  4.38226834e-02,  1.70510262e-04, -1.52004063e-01,\n",
       "        6.35735393e-02, -3.07299793e-01,  9.10957456e-02,  1.24099001e-01,\n",
       "        9.76602510e-02,  1.03076637e-01,  7.87738264e-02, -1.73119694e-01,\n",
       "        2.59633474e-02,  1.17113829e-01, -1.44173414e-01,  7.41567910e-02,\n",
       "        1.10890046e-01, -9.19506475e-02,  3.17143500e-02, -4.14134786e-02,\n",
       "        1.57312930e-01,  5.55452406e-02,  2.10436806e-03, -1.22481398e-01,\n",
       "        2.80369490e-01, -1.71775788e-01, -8.14135820e-02,  1.01233318e-01,\n",
       "       -2.15895474e-02, -1.69370532e-01, -2.34517246e-01, -1.95031241e-02,\n",
       "        3.87371421e-01,  1.26448303e-01, -1.13242902e-01, -2.56852880e-02,\n",
       "       -2.93686315e-02, -7.48278350e-02,  6.41726255e-02, -6.57257251e-03,\n",
       "       -3.63868475e-02, -1.12107500e-01, -1.22933969e-01,  3.58957797e-03,\n",
       "        2.59952813e-01, -7.79885352e-02, -1.86837763e-02,  2.25584045e-01,\n",
       "        4.89260554e-02, -6.09981269e-02,  8.55908841e-02, -1.21425986e-02,\n",
       "       -4.39759046e-02,  2.44942419e-02, -1.87204450e-01, -6.71581030e-02,\n",
       "        3.06459814e-02, -1.73021749e-01, -1.51744820e-02,  9.57959890e-02,\n",
       "       -1.88859224e-01,  2.09306806e-01, -2.68276781e-02, -3.40738967e-02,\n",
       "        6.43884838e-02, -3.79392058e-02, -1.14621297e-01,  1.78158656e-02,\n",
       "        2.56770074e-01, -1.98560268e-01,  2.46265918e-01,  1.65557176e-01,\n",
       "        4.32482436e-02,  1.65456533e-01,  4.34718579e-02,  1.46640882e-01,\n",
       "       -1.94956362e-02, -5.23635745e-02, -2.12971687e-01, -1.40632957e-01,\n",
       "       -2.78724134e-02,  9.85752046e-03,  4.69890982e-03,  1.15108512e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman_face_encoding = face_recognition.face_encodings(image_array1)[0]\n",
    "woman_face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdsqoI-nafP7",
    "outputId": "40ed4397-bb7a-4ce5-ecc4-984ea19d0fc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0516405 ,  0.14546923,  0.02807525, -0.03058147, -0.13201663,\n",
       "        0.09823276, -0.09290261, -0.07491422,  0.11423849, -0.05374532,\n",
       "        0.17672436, -0.00253267, -0.23354322,  0.09669919, -0.10853687,\n",
       "        0.13455331, -0.20274511, -0.08848572, -0.1758454 , -0.13610242,\n",
       "       -0.05469757,  0.08750116,  0.08281934, -0.07359078, -0.15687194,\n",
       "       -0.23084086, -0.07875912, -0.1136671 ,  0.16714752, -0.00172985,\n",
       "       -0.00725466, -0.0802847 , -0.21327253, -0.02874386,  0.03599843,\n",
       "        0.01643465, -0.09659414, -0.06703041,  0.17806211,  0.00518539,\n",
       "       -0.10319497,  0.04057913,  0.0896565 ,  0.23965582,  0.18405895,\n",
       "        0.02172235,  0.04684415, -0.11036564,  0.08473245, -0.25456113,\n",
       "        0.1272624 ,  0.12725623,  0.18159662,  0.14248927,  0.08285743,\n",
       "       -0.1080729 ,  0.06737694,  0.20034473, -0.08387953,  0.11374602,\n",
       "        0.14470401,  0.06365988, -0.04306559, -0.04762868,  0.21098186,\n",
       "        0.11215264, -0.07758902, -0.18247664,  0.23805252, -0.10803919,\n",
       "       -0.07138454,  0.03789591, -0.0532171 , -0.09498793, -0.25681758,\n",
       "        0.01591539,  0.39267915,  0.10462117, -0.14776967, -0.00303321,\n",
       "       -0.04356158, -0.0180154 , -0.01435511,  0.00459999, -0.18003121,\n",
       "       -0.08589467, -0.06244163,  0.02398437,  0.25415954, -0.09002876,\n",
       "        0.01904546,  0.16891092,  0.06746213, -0.05942041,  0.06814662,\n",
       "        0.10674956, -0.13694264, -0.025903  , -0.10465869,  0.04180485,\n",
       "        0.03416065, -0.15433779, -0.03539808,  0.11429142, -0.16507035,\n",
       "        0.21541029, -0.03933541, -0.05362553,  0.04556674,  0.03215502,\n",
       "       -0.04722693, -0.02760729,  0.24840321, -0.20851155,  0.2085481 ,\n",
       "        0.17349383, -0.00564384,  0.08665779,  0.06872489,  0.14833117,\n",
       "       -0.01714771,  0.09732926, -0.2090328 , -0.18792215, -0.05481   ,\n",
       "       -0.13345045, -0.09572566,  0.12309803])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_face_encoding = face_recognition.face_encodings(image_array2)[0]\n",
    "man_face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6yDEjljbIgE",
    "outputId": "e3a557f6-5f66-4893-b6aa-2494f370ff76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bottom_lip': [(47, 53),\n",
       "   (41, 56),\n",
       "   (36, 56),\n",
       "   (33, 57),\n",
       "   (29, 56),\n",
       "   (24, 56),\n",
       "   (19, 53),\n",
       "   (21, 53),\n",
       "   (29, 53),\n",
       "   (33, 53),\n",
       "   (36, 53),\n",
       "   (45, 53)],\n",
       "  'chin': [(-1, 24),\n",
       "   (0, 32),\n",
       "   (1, 40),\n",
       "   (2, 47),\n",
       "   (4, 55),\n",
       "   (9, 60),\n",
       "   (16, 64),\n",
       "   (25, 65),\n",
       "   (33, 65),\n",
       "   (41, 65),\n",
       "   (50, 63),\n",
       "   (57, 60),\n",
       "   (61, 54),\n",
       "   (63, 46),\n",
       "   (64, 38),\n",
       "   (64, 30),\n",
       "   (64, 22)],\n",
       "  'left_eye': [(12, 22), (16, 19), (20, 19), (24, 23), (20, 24), (15, 23)],\n",
       "  'left_eyebrow': [(5, 17), (9, 13), (15, 11), (21, 12), (27, 14)],\n",
       "  'nose_bridge': [(32, 20), (32, 26), (32, 32), (32, 37)],\n",
       "  'nose_tip': [(26, 42), (29, 43), (32, 43), (35, 42), (38, 42)],\n",
       "  'right_eye': [(40, 22), (44, 19), (48, 18), (52, 21), (49, 23), (44, 23)],\n",
       "  'right_eyebrow': [(36, 13), (42, 11), (48, 10), (54, 10), (58, 14)],\n",
       "  'top_lip': [(19, 53),\n",
       "   (25, 52),\n",
       "   (29, 51),\n",
       "   (33, 52),\n",
       "   (36, 51),\n",
       "   (41, 51),\n",
       "   (47, 53),\n",
       "   (45, 53),\n",
       "   (36, 53),\n",
       "   (33, 54),\n",
       "   (29, 53),\n",
       "   (21, 53)]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_landmarks_list1 = face_recognition.face_landmarks(image_array1)\n",
    "face_landmarks_list1\n",
    "#print(type(face_landmarks_list1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrwUVxnlbQER",
    "outputId": "05760f8c-40e8-4b25-f9bb-571df0960b3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bottom_lip': [(47, 51),\n",
       "   (42, 56),\n",
       "   (37, 57),\n",
       "   (33, 58),\n",
       "   (29, 57),\n",
       "   (23, 56),\n",
       "   (17, 52),\n",
       "   (19, 53),\n",
       "   (29, 54),\n",
       "   (33, 55),\n",
       "   (37, 54),\n",
       "   (45, 52)],\n",
       "  'chin': [(-2, 19),\n",
       "   (-2, 28),\n",
       "   (-1, 37),\n",
       "   (0, 46),\n",
       "   (2, 54),\n",
       "   (7, 61),\n",
       "   (14, 65),\n",
       "   (23, 68),\n",
       "   (32, 68),\n",
       "   (41, 67),\n",
       "   (49, 64),\n",
       "   (54, 59),\n",
       "   (58, 53),\n",
       "   (60, 45),\n",
       "   (61, 37),\n",
       "   (62, 28),\n",
       "   (62, 20)],\n",
       "  'left_eye': [(11, 19), (15, 18), (19, 18), (23, 21), (19, 21), (15, 21)],\n",
       "  'left_eyebrow': [(4, 14), (10, 11), (16, 10), (23, 10), (29, 13)],\n",
       "  'nose_bridge': [(33, 19), (33, 26), (34, 34), (34, 41)],\n",
       "  'nose_tip': [(25, 43), (29, 44), (33, 46), (37, 45), (40, 43)],\n",
       "  'right_eye': [(41, 21), (44, 18), (48, 18), (52, 20), (49, 21), (45, 21)],\n",
       "  'right_eyebrow': [(36, 13), (42, 10), (48, 10), (53, 11), (57, 15)],\n",
       "  'top_lip': [(17, 52),\n",
       "   (23, 52),\n",
       "   (29, 52),\n",
       "   (33, 53),\n",
       "   (37, 51),\n",
       "   (42, 52),\n",
       "   (47, 51),\n",
       "   (45, 52),\n",
       "   (37, 53),\n",
       "   (33, 54),\n",
       "   (29, 54),\n",
       "   (19, 53)]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_landmarks_list2 = face_recognition.face_landmarks(image_array2)\n",
    "face_landmarks_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsA_UsMuoO_k",
    "outputId": "f375e457-c6e4-447a-e442-146957a69bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9769991789545216, 5.3524100394119705, 6.118095464361208, 8.546789624890925, 10.830411719991975, 13.061920123755765, 14.336967047067914, 15.641157175390655, 17.063198433911154]\n"
     ]
    }
   ],
   "source": [
    "def find_euclidean_distance(face_features1, face_features2):\n",
    "  distance = 0.0\n",
    "  distance_array = []\n",
    "  for area in face_features1:\n",
    "    person1 = face_features1[area]\n",
    "    person2 = face_features2[area]\n",
    "    # print(person1)\n",
    "    # print(person2)\n",
    "    # print('----------------------------------------------')\n",
    "    distance += distance_between_feature(person1,person2);\n",
    "    distance_array.append(distance);\n",
    "    # print(person1)\n",
    "    # print(person2)\n",
    "    # print(distance)\n",
    "    # print('----------------------------------------------')\n",
    "  return distance_array\n",
    "\n",
    "print(find_euclidean_distance(face_landmarks_list1[0],face_landmarks_list2[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d7A9DtGFqkRc"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def distance_between_feature(point1, points2):\n",
    "  dist = 0.0\n",
    "  for i in range(0,len(point1)):\n",
    "    dist += distance.euclidean(point1[i], points2[i])\n",
    "  return dist/len(point1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imca7HwupZw1",
    "outputId": "a6e56db4-cb6d-4854-d1e1-f121c0fe92a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3,  3,  3],\n",
       "        [30, 30, 30],\n",
       "        [83, 83, 83],\n",
       "        ...,\n",
       "        [61, 61, 61],\n",
       "        [51, 51, 51],\n",
       "        [46, 46, 46]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [28, 28, 28],\n",
       "        [73, 73, 73],\n",
       "        ...,\n",
       "        [60, 60, 60],\n",
       "        [46, 46, 46],\n",
       "        [39, 39, 39]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [30, 30, 30],\n",
       "        [62, 62, 62],\n",
       "        ...,\n",
       "        [62, 62, 62],\n",
       "        [42, 42, 42],\n",
       "        [32, 32, 32]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[66, 66, 66],\n",
       "        [80, 80, 80],\n",
       "        [78, 78, 78],\n",
       "        ...,\n",
       "        [45, 45, 45],\n",
       "        [61, 61, 61],\n",
       "        [37, 37, 37]],\n",
       "\n",
       "       [[77, 77, 77],\n",
       "        [83, 83, 83],\n",
       "        [86, 86, 86],\n",
       "        ...,\n",
       "        [45, 45, 45],\n",
       "        [59, 59, 59],\n",
       "        [29, 29, 29]],\n",
       "\n",
       "       [[68, 68, 68],\n",
       "        [79, 79, 79],\n",
       "        [99, 99, 99],\n",
       "        ...,\n",
       "        [43, 43, 43],\n",
       "        [55, 55, 55],\n",
       "        [21, 21, 21]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array3 = face_recognition.load_image_file(\"/content/drive/MyDrive/images/ms_012_1.jpg\")\n",
    "image_array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MWFc_W6pvOS",
    "outputId": "3928f2f2-88f7-410c-eea8-43c7cda4719f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bottom_lip': [(42, 45),\n",
       "   (38, 50),\n",
       "   (33, 52),\n",
       "   (29, 53),\n",
       "   (25, 52),\n",
       "   (21, 49),\n",
       "   (17, 44),\n",
       "   (18, 44),\n",
       "   (26, 48),\n",
       "   (29, 48),\n",
       "   (33, 48),\n",
       "   (41, 45)],\n",
       "  'chin': [(1, 15),\n",
       "   (0, 24),\n",
       "   (1, 32),\n",
       "   (1, 40),\n",
       "   (4, 48),\n",
       "   (9, 54),\n",
       "   (14, 59),\n",
       "   (21, 63),\n",
       "   (29, 65),\n",
       "   (37, 64),\n",
       "   (44, 60),\n",
       "   (50, 56),\n",
       "   (56, 50),\n",
       "   (59, 42),\n",
       "   (60, 34),\n",
       "   (61, 25),\n",
       "   (62, 17)],\n",
       "  'left_eye': [(12, 14), (16, 13), (20, 13), (23, 16), (19, 16), (15, 16)],\n",
       "  'left_eyebrow': [(7, 8), (10, 4), (15, 4), (20, 4), (25, 6)],\n",
       "  'nose_bridge': [(31, 14), (31, 20), (31, 25), (30, 31)],\n",
       "  'nose_tip': [(24, 34), (27, 35), (30, 36), (33, 36), (36, 35)],\n",
       "  'right_eye': [(40, 16), (43, 14), (47, 14), (50, 15), (47, 16), (43, 16)],\n",
       "  'right_eyebrow': [(38, 7), (43, 5), (48, 4), (53, 6), (56, 9)],\n",
       "  'top_lip': [(17, 44),\n",
       "   (22, 42),\n",
       "   (26, 42),\n",
       "   (30, 42),\n",
       "   (33, 42),\n",
       "   (38, 43),\n",
       "   (42, 45),\n",
       "   (41, 45),\n",
       "   (33, 44),\n",
       "   (30, 44),\n",
       "   (26, 44),\n",
       "   (18, 44)]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_landmarks_list3 = face_recognition.face_landmarks(image_array3)\n",
    "face_landmarks_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXevE96np7kF",
    "outputId": "059ee8d3-fc82-48bb-cf66-2d2c8e37e8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.862826028806198, 11.7751116575253, 17.47637913037085, 25.468099810932202, 34.969772974159426, 40.019282730955815, 44.936070261994416, 54.539988209208985, 61.924158371423616]\n"
     ]
    }
   ],
   "source": [
    "print(find_euclidean_distance(face_landmarks_list2[0],face_landmarks_list3[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKDidir74fHE"
   },
   "source": [
    "Above vectors show that there exists a substantial distance between features if people are not related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CYrRQL-g4oc9"
   },
   "outputs": [],
   "source": [
    "#download dataset\n",
    "import requests, zipfile, io\n",
    "r = requests.get(\"http://www.kinfacew.com/dataset/KinFaceW-I.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OFlPwlwp9rMY"
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"http://www.kinfacew.com/dataset/KinFaceW-II.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDaaTzFm9xK3",
    "outputId": "0d5becdd-1382-469a-bd33-119c2ea58489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate a csv file for training and testing\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "CURRENT_DIRECTORY = \"content\"\n",
    "data = open(\"all-data.csv\",\"w\")\n",
    "\n",
    "data.write(\"image1,image2,relationship?\")\n",
    "data.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "REpJucld_c3K"
   },
   "outputs": [],
   "source": [
    "#define folder names\n",
    "folders = [\"father-dau\", \"mother-dau\", \"father-son\", \"mother-son\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Z4o6q_PoPmVY"
   },
   "outputs": [],
   "source": [
    "TOTAL_POSITIVE_SAMPLES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NdsVLrm0_-QQ"
   },
   "outputs": [],
   "source": [
    "FOLDER_BASE_PATH =  \"./dataset/KinFaceW-I/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "koKYlFRUGYh1"
   },
   "outputs": [],
   "source": [
    "data = open(\"all-data.csv\",\"a\")\n",
    "for folder in folders:\n",
    "  \n",
    "  for f in os.listdir(FOLDER_BASE_PATH+\"/\"+folder):\n",
    "    if f.endswith('1.jpg'):\n",
    "      TOTAL_POSITIVE_SAMPLES += 1\n",
    "      data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f[:-5]+'2.jpg'+ \",\" + '1\\n')\n",
    "data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "JEvnefARLN9u"
   },
   "outputs": [],
   "source": [
    "FOLDER_BASE_PATH =  \"./dataset/KinFaceW-II/images\"\n",
    "data = open(\"all-data.csv\",\"a\")\n",
    "for folder in folders:\n",
    "  \n",
    "  for f in os.listdir(FOLDER_BASE_PATH+\"/\"+folder):\n",
    "    if f.endswith('1.jpg'):\n",
    "      TOTAL_POSITIVE_SAMPLES += 1\n",
    "      data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f[:-5]+'2.jpg'+ \",\" + '1\\n')\n",
    "data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "q09bK0OOPuwZ"
   },
   "outputs": [],
   "source": [
    "TOTAL_NEGATIVE_NUMBERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hsUpBfXnLady"
   },
   "outputs": [],
   "source": [
    "#now try to generate data with no relationship\n",
    "NUMBER_OF_PAIRS = 10\n",
    "\n",
    "FOLDER_BASE_PATH =  \"./dataset/KinFaceW-II/images\"\n",
    "data = open(\"all-data.csv\",\"a\")\n",
    "for folder in folders:\n",
    "  file_names = os.listdir(FOLDER_BASE_PATH +\"/\"+folder)\n",
    "  if 'Thumbs.db' in file_names:\n",
    "    file_names.remove('Thumbs.db')\n",
    "  for f in os.listdir(FOLDER_BASE_PATH +\"/\"+folder):\n",
    "    if f.endswith('1.jpg'):\n",
    "      file_names.remove(f[:-5]+'2.jpg')\n",
    "      for i in range(0, NUMBER_OF_PAIRS):\n",
    "        TOTAL_NEGATIVE_NUMBERS += 1\n",
    "        data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+file_names[i] + \",\" + '0\\n')\n",
    "      file_names.append(f[:-5]+'2.jpg')\n",
    "    elif f.endswith('2.jpg') :\n",
    "      #print(f)\n",
    "      file_names.remove(f[:-5]+'1.jpg')\n",
    "      for i in range(0, NUMBER_OF_PAIRS):\n",
    "        TOTAL_NEGATIVE_NUMBERS += 1\n",
    "        data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+file_names[i] + \",\" + '0\\n')\n",
    "      file_names.append(f[:-5]+'1.jpg')\n",
    "\n",
    "data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "a9wlpJtEO-wa"
   },
   "outputs": [],
   "source": [
    "FOLDER_BASE_PATH =  \"./dataset/KinFaceW-I/images\"\n",
    "data = open(\"all-data.csv\",\"a\")\n",
    "for folder in folders:\n",
    "  file_names = os.listdir(FOLDER_BASE_PATH +\"/\"+folder)\n",
    "  if 'Thumbs.db' in file_names:\n",
    "    file_names.remove('Thumbs.db')\n",
    "  for f in os.listdir(FOLDER_BASE_PATH +\"/\"+folder):\n",
    "    if f.endswith('1.jpg'):\n",
    "      file_names.remove(f[:-5]+'2.jpg')\n",
    "      for i in range(0, NUMBER_OF_PAIRS):\n",
    "        TOTAL_NEGATIVE_NUMBERS += 1\n",
    "        data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+file_names[i] + \",\" + '0\\n')\n",
    "      file_names.append(f[:-5]+'2.jpg')\n",
    "    elif f.endswith('2.jpg') :\n",
    "      #print(f)\n",
    "      file_names.remove(f[:-5]+'1.jpg')\n",
    "      for i in range(0, NUMBER_OF_PAIRS):\n",
    "        TOTAL_NEGATIVE_NUMBERS += 1\n",
    "        data.write(FOLDER_BASE_PATH+\"/\"+folder+\"/\"+f + \",\" + FOLDER_BASE_PATH+\"/\"+folder+\"/\"+file_names[i] + \",\" + '0\\n')\n",
    "      file_names.append(f[:-5]+'1.jpg')\n",
    "\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbvrIwA6P3lf",
    "outputId": "284ff521-1672-444a-fae8-47b4328cf35f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples :  1533\n",
      "Negative samples :  30660\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive samples : \",TOTAL_POSITIVE_SAMPLES)\n",
    "print(\"Negative samples : \",TOTAL_NEGATIVE_NUMBERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pz9p5CQ7Qm8d",
    "outputId": "4d6e1235-3cd0-4f6f-d2b3-5735733a3018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "count = 0\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for entry in open('all-data.csv','r'):\n",
    "  if flag == 0 :\n",
    "    flag = 1\n",
    "    continue\n",
    "  if flag == 1 :\n",
    "    flag = 2\n",
    "    continue\n",
    "  splitted = entry.split(\",\")\n",
    "  image_1 = splitted[0]\n",
    "  # print(image_1)\n",
    "  # print(image_2)\n",
    "  image_2 = splitted[1]\n",
    "  image_array1 = face_recognition.load_image_file(image_1)\n",
    "  face_landmarks_list1 = face_recognition.face_landmarks(image_array1)\n",
    "\n",
    "  image_array2 = face_recognition.load_image_file(image_2)\n",
    "  face_landmarks_list2 = face_recognition.face_landmarks(image_array2)\n",
    "  #print(face_landmarks_list1, face_landmarks_list2)\n",
    "  if(len(face_landmarks_list1) != 0 and len(face_landmarks_list2) != 0):\n",
    "    count+=1\n",
    "    X.append(find_euclidean_distance(face_landmarks_list1[0], face_landmarks_list2[0]))\n",
    "    y.append(splitted[2])\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print('Count = ',count)\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face_similarity_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
